{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = [['Sunny','Warm','Normal','Strong','Warm','Same','+'],\n",
    " ['Sunny','Warm','High','Strong','Warm','Same','+'],\n",
    " ['Rainy','Cold','High','Strong','Warm','Change','-'],\n",
    " ['Sunny','Warm','High','Strong','Cool','Change','+']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = ['0','0','0','0','0','0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def positiveInstances():\n",
    "    return [x for x in X if x[-1]=='+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in positiveInstances():\n",
    "    for i in range(len(h)):\n",
    "        if h[i]!=x[i]:\n",
    "            if h[i]=='0':\n",
    "                h[i]=x[i]\n",
    "            else:\n",
    "                h[i]='!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunny', 'Warm', '!', 'Strong', '!', '!']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement **List-Then-Eliminate** and **Candidate Elimination** below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('-', '-', '-', '-', '-', '-')]\n",
      "[('sunny', 'warm', 'normal', 'strong', 'warm', 'same')]\n",
      "[('sunny', 'warm', 'normal', 'strong', 'warm', 'same')]\n",
      "[('sunny', 'warm', '?', 'strong', 'warm', 'same')]\n",
      "[('?', '?', '?', '?', '?', '?')]\n",
      "[('sunny', '?', '?', '?', '?', '?'), ('cloudy', '?', '?', '?', '?', '?'), ('?', 'warm', '?', '?', '?', '?'), ('?', '?', 'normal', '?', '?', '?'), ('?', '?', '?', 'weak', '?', '?'), ('?', '?', '?', '?', 'cold', '?'), ('?', '?', '?', '?', '?', 'same')]\n",
      "[('sunny', 'warm', '?', 'strong', 'warm', 'same')]\n",
      "[('sunny', 'warm', '?', 'strong', '?', '?')]\n",
      "[('sunny', 'warm', '?', 'strong', '?', '?')]\n",
      "[('sunny', '?', '?', '?', '?', '?'), ('?', 'warm', '?', '?', '?', '?')]\n"
     ]
    }
   ],
   "source": [
    "# Candidate Elimination\n",
    "\n",
    "class Holder:\n",
    "    factors={}  #Un dictionar gol\n",
    "    attributes = ()  #Parametrii sunt declarati\n",
    "\n",
    "    def __init__(self,attr):  #\n",
    "        self.attributes = attr\n",
    "        for i in attr:\n",
    "            self.factors[i]=[]\n",
    "            \n",
    "            \n",
    "    def add_values(self,factor,values):\n",
    "        self.factors[factor]=values\n",
    "\n",
    "class CandidateElimination:\n",
    "    Positive={} #Dictionarul pozitiv (gol)\n",
    "    Negative={} #Dictionarul negativ (gol)\n",
    "    \n",
    "    def __init__(self,data,fact):\n",
    "        self.num_factors = len(data[0][0])\n",
    "        self.factors = fact.factors\n",
    "        self.attr = fact.attributes\n",
    "        self.dataset = data\n",
    "        \n",
    "        #print self.attr\n",
    "        \n",
    "    def run_algorithm(self):\n",
    "#        print self.dataset\n",
    "\n",
    "        # Limita specifica si generala\n",
    "\n",
    "        G = self.initializeG()\n",
    "        S = self.initializeS()\n",
    "        \n",
    "\n",
    "        # Popularea listei in variabila trial_set \n",
    "\n",
    "        count=0\n",
    "        for trial_set in self.dataset:\n",
    "            if self.is_positive(trial_set):\n",
    "                G = self.remove_inconsistent_G(G,trial_set[0]) # Daca trial_set este alcatuit din exemple pozitive inlaturam datele inconsistente din limita generala\n",
    "                S_new = S[:]\n",
    "                print S_new\n",
    "                for s in S:\n",
    "                    if not self.consistent(s,trial_set[0]):\n",
    "                        S_new.remove(s)\n",
    "                        generalization = self.generalize_inconsistent_S(s,trial_set[0])\n",
    "                        generalization = self.get_general(generalization,G)\n",
    "                        if generalization:\n",
    "                            S_new.append(generalization)\n",
    "                    S = S_new[:]\n",
    "                    S = self.remove_more_general(S)\n",
    "                   \n",
    "                    print S\n",
    "            else:\n",
    "                S = self.remove_inconsistent_S(S,trial_set[0]) #Daca este negativ inlaturam datele inconsistente din limita specifica\n",
    "                G_new = G[:]\n",
    "                print G_new\n",
    "                for g in G:\n",
    "                    if self.consistent(g,trial_set[0]):\n",
    "                        G_new.remove(g)\n",
    "                        specializations = self.specialize_inconsistent_G(g,trial_set[0])\n",
    "                        specializationss = self.get_specific(specializations,S)\n",
    "                        if specializations != []:\n",
    "                            G_new += specializations\n",
    "                    G = G_new[:] \n",
    "                    print G\n",
    "                    G = self.remove_more_specific(G)\n",
    "        \n",
    "        print S\n",
    "        print G\n",
    "    \n",
    "    def initializeS(self):\n",
    "        # Limita specifica\n",
    "        S = tuple(['-' for factor in range(self.num_factors)])\n",
    "        return [S]\n",
    "\n",
    "    def initializeG(self):\n",
    "        # Limita generala\n",
    "        G = tuple(['?' for factor in range(self.num_factors)])\n",
    "        return [G]\n",
    "\n",
    "    def is_positive(self,trial_set):\n",
    "        # Verifica daca un trial_set dat este pozitiv\n",
    "        if trial_set[1] == 'Y':\n",
    "            return True\n",
    "        elif trial_set[1] == 'N':\n",
    "            return False\n",
    "        else:\n",
    "            raise TypeError(\"invalid target value\")\n",
    "\n",
    "    def is_negative(self,trial_set):\n",
    "        # Verifica daca un trial_set dat este negativ\n",
    "        if trial_set[1] == 'N':\n",
    "            return False\n",
    "        elif trial_set[1] == 'Y':\n",
    "            return True\n",
    "        else:\n",
    "            raise TypeError(\"invalid target value\")\n",
    "\n",
    "    def match_factor(self,value1,value2):\n",
    "        # Check for the factors values match, necessary while checking the consistency of training trial_set with the hypothesis\n",
    "        if value1 == '?' or value2 == '?':\n",
    "            return True\n",
    "        elif value1 == value2 :\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def consistent(self,hypothesis,instance):\n",
    "        # Verifica daca instanta este parte din ipoteza \n",
    "        for i,factor in enumerate(hypothesis):\n",
    "            if not self.match_factor(factor,instance[i]):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def remove_inconsistent_G(self,hypotheses,instance):\n",
    "        # Pentru un trial_set pozitiv ipoteza inconsistenta din G trebuie inlaturata\n",
    "        G_new = hypotheses[:]\n",
    "        for g in hypotheses:\n",
    "            if not self.consistent(g,instance):\n",
    "                G_new.remove(g)\n",
    "        return G_new\n",
    "\n",
    "    def remove_inconsistent_S(self,hypotheses,instance):\n",
    "        # Pentru un trial_set negativ ipoteza inconsistenta din S trebuie inlaturata\n",
    "        S_new = hypotheses[:]\n",
    "        for s in hypotheses:\n",
    "            if self.consistent(s,instance):\n",
    "                S_new.remove(s)\n",
    "        return S_new\n",
    "        \n",
    "    def remove_more_general(self,hypotheses):\n",
    "        # Dupa generalizarea S pentru un trial_set pozitiv, ipoteza S mai generala decat altele in S este inlaturata\n",
    "        S_new = hypotheses[:]\n",
    "        for old in hypotheses:\n",
    "            for new in S_new:\n",
    "                if old!=new and self.more_general(new,old):\n",
    "                    S_new.remove[new]\n",
    "        return S_new\n",
    "\n",
    "    def remove_more_specific(self,hypotheses):\n",
    "        # Dupa specializarea G pentru un trial_set negativ, ipoteza G mai specifica decat altele in G este inlaturata\n",
    "        G_new = hypotheses[:]\n",
    "        for old in hypotheses:\n",
    "            for new in G_new:\n",
    "                if old!=new and self.more_specific(new,old):\n",
    "                    G_new.remove[new]\n",
    "        return G_new\n",
    "\n",
    "    def generalize_inconsistent_S(self,hypothesis,instance):\n",
    "        # Atunci cand se gaseste o ipoteza inconsistenta pentru trial_set-ul pozitiv in limita specifica trebuie generalizata pentru a fi consistenta cu trial_set-ul\n",
    "        hypo = list(hypothesis)\n",
    "        for i,factor in enumerate(hypo):\n",
    "            if factor == '-':\n",
    "                hypo[i] = instance[i]\n",
    "            elif not self.match_factor(factor,instance[i]):\n",
    "                hypo[i] = '?'\n",
    "        generalization = tuple(hypo)\n",
    "        return generalization\n",
    "\n",
    "    def specialize_inconsistent_G(self,hypothesis,instance):\n",
    "        # Atunci cand se gaseste o ipoteza inconsistenta pentru trial_set-ul negativ in limita generala trebuie specializata pentru a fi consistenta cu trial_set-ul\n",
    "        specializations = []\n",
    "        hypo = list(hypothesis)\n",
    "        for i,factor in enumerate(hypo):\n",
    "            if factor == '?':\n",
    "                values = self.factors[self.attr[i]]\n",
    "                for j in values:\n",
    "                    if instance[i] != j:\n",
    "                        hyp=hypo[:]\n",
    "                        hyp[i]=j\n",
    "                        hyp=tuple(hyp)\n",
    "                        specializations.append(hyp)\n",
    "        return specializations\n",
    "\n",
    "   \n",
    "    def get_general(self,generalization,G): \n",
    "        for g in G:\n",
    "            if self.more_general(g,generalization):\n",
    "                return generalization\n",
    "        return None\n",
    "\n",
    "    def get_specific(self,specializations,S):\n",
    "        valid_specializations = []\n",
    "        for hypo in specializations:\n",
    "            for s in S:\n",
    "                if self.more_specific(s,hypo) or s==self.initializeS()[0]:\n",
    "                    valid_specializations.append(hypo)\n",
    "        return valid_specializations\n",
    "\n",
    "   \n",
    "    def get_version_space(self,specific,general):\n",
    "        # Avand limita generala si specifica, evaluam VS dintre acestea\n",
    "        while get_order(VS):  \n",
    "            for hypothesis in VS[:]:\n",
    "                hypo = list(hypothesis)\n",
    "                for i,factor in enumerate(hypo):\n",
    "                    if factor != '?':\n",
    "                        hyp=hypo[:]\n",
    "                        hyp[i]='?'\n",
    "                        if self.exists_general(hyp,general)and self.exists_specific(hyp,specific):\n",
    "                            VS.append(tuple(hyp))\n",
    "\n",
    "        return VS\n",
    "\n",
    "    def get_order(self,hypothesis):\n",
    "        pass\n",
    "    \n",
    "    def more_general(self,hyp1,hyp2):\n",
    "        # Verifica daca hyp1 este mai generala decat hyp2\n",
    "        hyp = zip(hyp1,hyp2)\n",
    "        for i,j in hyp:\n",
    "            if i == '?':\n",
    "                continue\n",
    "            elif j == '?':\n",
    "                if i != '?':\n",
    "                    return False\n",
    "            elif i != j:\n",
    "                return False\n",
    "            else:                       \n",
    "                continue\n",
    "        return True\n",
    "\n",
    "    def more_specific(self,hyp1,hyp2):\n",
    "        # Daca hyp1 este mai specific decat hyp2 este echivalentul la hyp2 mai generala decat hyp1\n",
    "        return self.more_general(hyp2,hyp1)\n",
    "\n",
    "\n",
    "\n",
    "dataset=[(('sunny','warm','normal','strong','warm','same'),'Y'),(('sunny','warm','high','strong','warm','same'),'Y'),(('rainy','cold','high','strong','warm','change'),'N'),(('sunny','warm','high','strong','cool','change'),'Y')]\n",
    "attributes =('Sky','Temp','Humidity','Wind','Water','Forecast')\n",
    "\n",
    "\n",
    "f = Holder(attributes)\n",
    "f.add_values('Sky',('sunny','rainy','cloudy'))\n",
    "f.add_values('Temp',('cold','warm'))\n",
    "f.add_values('Humidity',('normal','high'))\n",
    "f.add_values('Wind',('weak','strong'))\n",
    "f.add_values('Water',('warm','cold'))\n",
    "f.add_values('Forecast',('same','change'))\n",
    "a = CandidateElimination(dataset,f)\n",
    "a.run_algorithm()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
